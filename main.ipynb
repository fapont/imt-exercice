{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement d'un modèle de Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce notebook est d'entraîner un modèle de Machine Learning pour prédire le prix de vente d'un bien immobilier à partir de ses caractéristiques.\n",
    "\n",
    "Les données utilisées pour notre TP sont issues du jeu de données publique des [valeurs foncières françaises de 2021](https://www.data.gouv.fr/en/datasets/demandes-de-valeurs-foncieres/). Ces données ont été retravaillées pour vous et se trouvent dans le fichier `data.csv`.\n",
    "\n",
    "Nous allons suivre les étapes suivantes:\n",
    "1. Charger les données\n",
    "2. Analyser les données\n",
    "3. Préparer les données\n",
    "4. Entraîner un modèle\n",
    "5. Évaluer le modèle\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de manipuler notre dataset nous allons utiliser la librairie `pandas`. Cette librairie permet de manipuler des données tabulaires (comme un fichier Excel par exemple).\n",
    "\n",
    "Cette librairie est très utilisée dans le monde du Machine Learning car elle permet de manipuler facilement des données et de les préparer. Il est très important pour un Data Scientist de savoir manipuler des données avec `pandas`.\n",
    "\n",
    "Lien vers la documentation de `pandas`: https://pandas.pydata.org/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: importer la librairie pandas\n",
    "# import ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: lire le fichier data.csv en utilisant la fonction read_csv de pandas\n",
    "# df = ... \n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En exécutant les cellules ci-dessus vous avez pu charger le dataset dans un DataFrame `df`. Un DataFrame est un objet de la librairie `pandas` qui permet de manipuler des données tabulaires.\n",
    "\n",
    "L'objectif des cellules suivantes est d'analyser notre dataset afin de mieux le comprendre et de préparer nos données pour l'entraînement de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: afficher les 5 premières lignes du dataframe grâce à la méthode head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: afficher une analyse statistique du dataframe grâce à la méthode describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculer la moyenne du prix des maisons ayant pour postcode 75.\n",
    "# Il est possible facilement filtrer les données sur une colonne et de sélectionner une colonne en particulier\n",
    "# Lien d'aide: https://www.educative.io/answers/how-to-filter-pandas-dataframe-by-column-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (difficile): trier les postcodes par ordre croissant de prix moyen des maisons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données pour l'entraînement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de pouvoir entraîner notre modèle nous devons préparer nos données. Cette étape est très importante et peut prendre beaucoup de temps (en général la majorité du temps). En effet, les données que nous avons récupérées ne sont pas forcément exploitables directement par notre modèle. Il est donc nécessaire de les transformer afin de pouvoir les utiliser.\n",
    "\n",
    "Il est important de distinguer différents types de variables:\n",
    "\n",
    "- Les variables `catégorielles` qui représentent des catégories (ex: type de bien immobilier, code postal, ...). Parmi les variables catégorielles on distingue 2 sous-catégories:\n",
    "\n",
    "  - Les variables `nominales` qui ne peuvent pas être ordonnées (ex: type de bien immobilier, code postal)\n",
    "  - Les variables `ordinales` qui peuvent être ordonnées (ex: mention au bac: Nul, Moins nul, Encore moins nul, ...)\n",
    "\n",
    "- Les variables `numériques` qui représentent des valeurs numériques (ex: surface, nombre de pièces, ...). Parmi les variables numériques on distingue 2 sous-catégories:\n",
    "  - Les variables `continues` qui peuvent prendre n'importe quelle valeur (ex: surface, ...)\n",
    "  - Les variables `discrètes` qui ne peuvent prendre qu'un nombre fini de valeurs réelles possibles (ex: nombre de pièces, ...)\n",
    "\n",
    "Pour plus d'informations sur les variables vous pouvez consulter [cette page](https://www150.statcan.gc.ca/n1/edu/power-pouvoir/ch8/5214817-fra.htm) par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Par soucis de simplicité nous n'allons pour le moment pas nous \n",
    "# intéresser à la colonne `postcode`. Supprimer la colonne `postcode` du dataframe\n",
    "# en utilisant la méthode drop\n",
    "# Note: créer une nouvelle variable pour stocker le nouveau dataframe\n",
    "# data = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des variables catégorielles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est important de comprendre que les modèles de Machine Learning ne peuvent pas prendre en entrée n'importe quel type de données. Dans notre cas, notre modèle ne peut pas prendre en entrée des chaînes de caractères (ex: `Maison`, `Appartement`, ...). Il est donc nécessaire de transformer ces chaînes de caractères en nombres. On appelle cette étape `encodage`.\n",
    "\n",
    "Il existe plusieurs manières d'encoder des données: `label encoding`, `one-hot encoding`, ... (pour plus d'informations vous pouvez consulter [cette page](https://inria.github.io/scikit-learn-mooc/python_scripts/03_categorical_pipeline.html)).\n",
    "\n",
    "Dans notre cas, étant donné que notre variable `house_type` ne peut prendre que 2 valeurs (`Maison` ou `Appartement`) nous allons utiliser un `label encoding`. Cet encodage consiste à remplacer chaque valeur unique de notre variable par un nombre. Dans notre cas, nous allons remplacer `Maison` par `0` et `Appartement` par `1`.\n",
    "\n",
    "De cette manière notre modèle pourra prendre en entrée des nombres et non plus des chaînes de caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: créer un objet de type `LabelEncoder` de la librairie sklearn et \n",
    "# l'assigner à la variable `label_encoder`. Cet objet doit être `fit` sur la \n",
    "# colonne `house_type`\n",
    "# Lien d'aide: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "# from sklearn.preprocessing ...\n",
    "# label_encoder = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérifier que l'exécution de cette cellule produit: [1, 0, 0]\n",
    "label_encoder.transform(['Maison', 'Appartement', 'Appartement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remplacer la colonne `house_type` dans le dataframe `data` par une\n",
    "# la version encodée de cette colonne. Pour cela, utiliser la méthode `transform`\n",
    "# de l'objet `label_encoder`\n",
    "\n",
    "# data['house_type'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier que notre DataFrame ne contient que des colonnes numériques\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des données d'entraînement et de test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Machine Learning il est très important de séparer nos données en 2 parties:\n",
    "\n",
    "- Les données d'entraînement qui vont nous permettre d'entraîner notre modèle\n",
    "- Les données de test qui vont nous permettre d'évaluer les performances de notre modèle\n",
    "\n",
    "Il est très important de ne pas utiliser les données de test pour entraîner notre modèle. En effet, si nous utilisions les données de test pour entraîner notre modèle, nous pourrions avoir l'impression que notre modèle est très performant alors qu'en réalité il ne généralise pas bien et ne sera pas performant sur de nouvelles données.\n",
    "\n",
    "Cette séparation permet donc d'évaluer la capacité de notre modèle à généraliser sur de nouvelles données. En général, on utilise 80% des données pour l'entraînement et 20% pour le test (cela peut varier en fonction de la taille de notre dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: créer deux variables X et y qui contiennent respectivement les features\n",
    "# et les labels. Pour cela, utiliser la méthode `drop` de pandas pour supprimer\n",
    "# la colonne `value` du dataframe `data` et l'assigner à la variable X.\n",
    "# La variable y doit contenir uniquement la colonne `value` du dataframe `data`\n",
    "# X, y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: importer la fonction `train_test_split` de la librairie sklearn et séparer\n",
    "# les données en un jeu d'entraînement et un jeu de test. Le jeu de test doit contenir\n",
    "# 20% des données.\n",
    "# from sklearn.model_selection ...\n",
    "# X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Vérifier que la dataframe d'entraînement contient 879792 lignes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: la fonction `train_test_split` de `scikit-learn` effectue un tirage aléatoire des données. Il est donc possible que vous obteniez des résultats différents de ceux présentés dans ce notebook. Sauf si vous avez fixé la graine aléatoire `random_state` (voir [cette page](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On appelle `modèle` de Machine Learning une fonction mathématique qui prend en entrée des données et qui renvoie une prédiction. Dans notre cas, notre modèle prendra en entrée les caractéristiques d'un bien immobilier (surface, nombre de pièces, ...) et renverra une estimation du prix de ce bien.\n",
    "\n",
    "On distingue 2 grandes familles de modèles de Machine Learning:\n",
    "\n",
    "- Les modèles de `régression` qui permettent de prédire une valeur continue (ex: prix d'un bien immobilier)\n",
    "- Les modèles de `classification` qui permettent de prédire une valeur discrète (ex: prédire si un mail est un spam ou non)\n",
    "\n",
    "Dans notre cas nous allons utiliser un modèle de régression linéaire. Ce modèle est très simple et permet de prédire une valeur continue à partir d'une combinaison linéaire de nos variables d'entrée. Dans notre cas, notre modèle prendra la forme suivante:\n",
    "\n",
    "$$\n",
    "prix = \\beta_0 + \\beta_1* surface + \\beta_2 * nbRoom + \\beta_3 * gardenArea + \\beta_4 * houseType + \\beta_5 * postcode\n",
    "$$\n",
    "\n",
    "Où les $\\beta_i,$ sont des paramètres du modèle que nous allons apprendre à partir de nos données d'entraînement.\n",
    "\n",
    "Pour plus d'informations sur les modèles de régression linéaire vous pouvez consulter [cette page](https://www.voxco.com/fr/blog/comment-calculer-la-regression-lineaire/) qui explique comment calculer les paramètres de notre modèle.\n",
    "\n",
    "_Note_: dans notre cas nous utiliserons une régression linéaire multiple car nous avons plusieurs variables d'entrée. Si nous n'avions qu'une seule variable d'entrée nous parlerions de régression linéaire simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: importer la classe `LinearRegression` de la librairie sklearn et entraîner\n",
    "# un modèle de régression linéaire sur les données d'entraînement. Ce modèle sera\n",
    "# assigné à la variable `model`\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5294279.74148212])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérifier que l'exécution de cette cellule produit: 8908694 (dans le ca où \n",
    "# la variable `random_state` de la fonction `train_test_split` est égale à 42)\n",
    "model.predict(X_train.iloc[0:1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà ! Vous avez entraîné votre premier modèle de Machine Learning (ou pas) ! Vous pouvez maintenant l'utiliser pour prédire le prix de vente d'un bien immobilier à partir de ses caractéristiques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation du modèle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Machine Learning il est très important d'évaluer les performances de notre modèle. En effet, il est possible que notre modèle ne soit pas performant et ne soit pas capable de prédire correctement le prix de vente d'un bien immobilier. Afin de connaître les performances de notre modèle nous allons utiliser une métrique appelée `MAE` (Mean Absolute Error). Cette métrique permet de mesurer l'erreur moyenne de notre modèle. Plus cette métrique est faible, plus notre modèle est performant.\n",
    "\n",
    "Il existe de nombreuses autres métriques que nous pourrions utiliser (ex: `RMSE` qui est très utilisée). Pour plus d'informations vous pouvez consulter [cette page](https://scikit-learn.org/stable/modules/model_evaluation.html). Certaines méthodes d'évaluation sont plus adaptées à certains types de problèmes. Par exemple, pour un problème de classification on utilisera plutôt la métrique `accuracy` qui permet de mesurer le taux de bonnes prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO importer la fonction `mean_absolute_error` de la librairie sklearn et\n",
    "# calculer l'erreur absolue moyenne sur le jeu de test\n",
    "\n",
    "# from sklearn.metrics import ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur obtenue est exprimée en euros. Cela peut sembler beaucoup mais il faut garder en tête que nous avons utilisé un modèle très simple. Il est possible d'obtenir de bien meilleurs résultats en utilisant des modèles plus complexes. ou en transformant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: importer un modèle de régression basé sur les arbres de décision\n",
    "# (DecisionTreeRegressor) et entraîner ce modèle sur les données d'entraînement\n",
    "# assigner le modèle à la variable `model2`. Utilisez le même procédé que pour\n",
    "# la régression linéaire\n",
    "# Lien d'aide: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculer l'erreur absolue moyenne sur le jeu de test pour le modèle 2\n",
    "# et comparer avec le modèle 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarquer plusieurs choses:\n",
    "- Le modèle est plus performant que le modèle de régression linéaire. Ce n'est pas parfait mais c'est un bon début !\n",
    "- Il est possible d'améliorer les performances de notre modèle en utilisant un modèle plus complexe (ex: `RandomForestRegressor` ou `GradientBoostingRegressor` de `scikit-learn`).\n",
    "- Il est possible de modifier les hyperparamètres de notre modèle afin d'obtenir de meilleurs résultats. Voir sur la documentation\n",
    "- Il est très difficile d'estimer le prix de vente d'un bien immobilier à partir des quelques caractéristiques que nous avons. Afin que notre modèle soit plus performant il faudrait utiliser plus de données (ex: code postal, nombre de salles de bain, année de construction, ...). Une phrase à retenir `Garbage in, garbage out` (si on donne de mauvaises données à notre modèle, il ne pourra pas faire de miracle)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'une pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Précédemment, nous avons comparé 2 modèles et nous avons décidé de garder le\n",
    "plus performant. Afin de créer le modèle le plus pertinent possible pour notre\n",
    "application de prédiction de prix immobilier, nous allons réentraîner le modèle\n",
    "sélectionné sur l'ensemble des données (jeu d'entraînement + jeu de test).\n",
    "\n",
    "Nous allons également créer une pipeline qui permettra de transformer nos données avant de les donner en entrée de notre modèle. Cela nous sera très utile pour transformer de nouvelles données avant de les donner en entrée de notre modèle.\n",
    "\n",
    "En réalité, grâce à la pipeline nous allons réaliser toutes les étapes précédentes en quelques lignes de code. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: à finir et leur donner le code tout fait pour créer la pipeline\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "# Cette pipeline permet d'encoder les données catégorielles et d'entraîner\n",
    "# un modèle de régression linéaire\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('encoder', LabelEncoder(), ['house_type'])\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', column_transformer)\n",
    "    ('model', LinearRegression())\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde du modèle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de pouvoir utiliser notre modèle dans une applicationnous allons le sauvegarder dans un fichier. Pour cela nous allons utiliser la librairie `pickle` qui permet de sauvegarder des objets Python dans un fichier.\n",
    "\n",
    "Cette étape est très importante car elle nous permet de ne pas avoir à réentrainer notre modèle à chaque fois que nous voulons l'utiliser. En effet, l'entraînement d'un modèle peut prendre beaucoup de temps (en fonction de la taille de notre dataset et de la complexité de notre modèle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialisation de la pipeline entraînée\n",
    "# Cette cellule va créer un fichier `pipeline.pkl` qui contient la pipeline \n",
    "# entraînée. Ce fichier pourra être ensuite chargé et réutilisé\n",
    "import pickle\n",
    "\n",
    "with open('pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO vérifier que vous arrivez à charger la pipeline dans la variable `loaded_model`\n",
    "# et que vous pouvez effectuer des prédictions avec cette pipeline\n",
    "loaded_model = pickle.load(open(\"pipeline.pkl\", 'rb'))\n",
    "# loaded_model.predict ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92780c23da17ac90b81e0f4fce58a2d474d49d37a808f4d3a79a2ccd38f26465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
