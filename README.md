# Objectif

Cr√©ation d'une application web permettant de pr√©dire le prix d'un bien immobilier √† partir de certaines caract√©ristiques. L'objectif de ce TP est de vous familiariser avec les probl√©matiques de d√©ploiement d'un mod√®le de Machine Learning. Ce TP se d√©roule en 2 parties:

1. Cr√©ation d'un mod√®le de Machine Learning permettant de pr√©dire le prix d'un bien immobilier
2. Cr√©ation d'une webapp permettant de faire appel √† ce mod√®le

## Mod√®le de Machine Learning

### Introduction

On appelle `mod√®le` de Machine Learning une fonction math√©matique qui prend en entr√©e des donn√©es et qui renvoie une pr√©diction. Dans notre cas, notre mod√®le prendra en entr√©e les caract√©ristiques d'un bien immobilier (surface, nombre de pi√®ces, ...) et renverra une estimation du prix de ce bien.

On distingue 2 grandes familles de mod√®les de Machine Learning:

- Les mod√®les de `r√©gression` qui permettent de pr√©dire une valeur continue (ex: prix d'un bien immobilier)
- Les mod√®les de `classification` qui permettent de pr√©dire une valeur discr√®te (ex: pr√©dire si un mail est un spam ou non)

Dans notre cas nous allons utiliser un mod√®le de r√©gression lin√©aire. Ce mod√®le est tr√®s simple et permet de pr√©dire une valeur continue √† partir d'une combinaison lin√©aire de nos variables d'entr√©e. Dans notre cas, notre mod√®le prendra la forme suivante:

```
prix = w1 * surface + w2 * nb_room + w3 * garden_area + w4 * house_type + w5 * postcode + b
```

O√π `w1`, `w2`, `w3`, `w4`, `w5` et `b` sont des param√®tres que l'on va chercher √† apprendre √† partir de nos donn√©es d'entrainement.

Pour plus d'informations sur les mod√®les de r√©gression lin√©aire vous pouvez consulter [cette page](https://www.voxco.com/fr/blog/comment-calculer-la-regression-lineaire/) qui explique comment calculer les param√®tres de notre mod√®le.

_Note_: dans notre cas nous utiliserons une r√©gression lin√©aire multiple car nous avons plusieurs variables d'entr√©e. Si nous n'avions qu'une seule variable d'entr√©e nous parlerions de r√©gression lin√©aire simple.

### Pr√©paration des donn√©es

Avant de pouvoir entra√Æner notre mod√®le nous devons pr√©parer nos donn√©es. Cette √©tape est tr√®s importante et peut prendre beaucoup de temps (en g√©n√©ral la majorit√© du temps). En effet, les donn√©es que nous avons r√©cup√©r√©es ne sont pas forc√©ment exploitables directement par notre mod√®le. Il est donc n√©cessaire de les transformer afin de pouvoir les utiliser.

#### Encodage des variables cat√©gorielles

Il est important de comprendre que les mod√®les de Machine Learning ne peuvent pas prendre en entr√©e n'importe quel type de donn√©es. Dans notre cas, notre mod√®le ne peut pas prendre en entr√©e des cha√Ænes de caract√®res (ex: `Maison`, `Appartement`, ...). Il est donc n√©cessaire de transformer ces cha√Ænes de caract√®res en nombres. On appelle cette √©tape `encodage`.

Il existe plusieurs mani√®res d'encoder des donn√©es: `label encoding`, `one-hot encoding`, ... (pour plus d'informations vous pouvez consulter [cette page](https://inria.github.io/scikit-learn-mooc/python_scripts/03_categorical_pipeline.html)).

Dans notre cas, √©tant donn√© que notre variable `house_type` ne peut prendre que 2 valeurs (`Maison` ou `Appartement`) nous allons utiliser un `label encoding`. Cet encodage consiste √† remplacer chaque valeur unique de notre variable par un nombre. Dans notre cas, nous allons remplacer `Maison` par `0` et `Appartement` par `1`.

De cette mani√®re notre mod√®le pourra prendre en entr√©e des nombres et non plus des cha√Ænes de caract√®res.

#### Normalisation des variables num√©riques

# Ressources

Pour r√©aliser ce TP vous aurez besoin d'avoir [Python](https://www.python.org/downloads/) install√© sur votre ordinateur, ainsi que de pouvoir ouvrir et ex√©cuter un Jupyter notebook. Nous vous conseillons d'installer [VsCode](https://code.visualstudio.com/), un √©diteur de code d√©velopp√© par Microsoft, afin de faciliter ce travail.

De plus vous aurez besoin d'√™tre familier avec les √©l√©ments suivants:

- [`Scikit-Learn`](https://scikit-learn.org/stable/) qui est une librairie Python permettant de facilement utiliser des mod√®les de Machine Learning.
- [`Pickle`](https://docs.python.org/3/library/pickle.html) permet de s√©rialiser des objets Python (transformation d'une structure Python en un fichier pouvant √™tre stock√© puis reconstruit).
- [`Pandas`](https://pandas.pydata.org/) une librairie permettant de manipuler des DataFrame tr√®s facilement.
- [`Flask`](https://flask.palletsprojects.com/en/2.2.x/) est un framework de d√©veloppement d'appication Web id√©al pour cr√©er des APIs.

Afin d'installer facilement tous les packages n√©cessaires vous pouvez utiliser la commande:

```
pip install -r requirements.txt
ou
python3 -m pip install -r requirements.txt
```

# Donn√©es

Les donn√©es utilis√©es pour notre TP sont issues du jeu de donn√©es publique des [valeurs fonci√®res fran√ßaises de 2021](https://www.data.gouv.fr/en/datasets/demandes-de-valeurs-foncieres/). Ces donn√©es ont √©t√© retravaill√©es pour vous et se trouvent dans le fichier `data.csv`.

# D√©roulement du TP

## Partie 1: cr√©ation du mod√®le

**Dans un premier temps nous supprimerons la variable `postcode`**

1. Pour l'instant le preprocessing de nos donn√©es se limite √† un encodage de la variable `house_type`. Compl√©tez la fonction `transform_house_type` (de mani√®re simple, on cherche √† cr√©er une fonction d'encodage de notre variable)

2. Lors de ce tp nous ne cherchons pas √† optimiser notre mod√®le avec les meilleurs hyperparam√®tres. De ce fait, s√©parez vos pr√©dicteurs de la valeur √† pr√©dire et entra√Ænez un mod√®le lin√©aire sur toute les donn√©es. Vous pouvez utiliser la [r√©gression lin√©aire](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).

3. Lorsque votre mod√®le est entra√Æn√©, sauvegarder ce dernier au format [`pickle`](https://docs.python.org/3/library/pickle.html), appelez le `model.pkl` par exemple. Cette m√©thode vous permet de sauvegarder votre mod√®le entra√Æn√© dans un fichier qui pourra √™tre utilis√© dans notre application web.

## Partie 2: cr√©ation d'une webapp

Afin de d√©velopper le backend de notre application web nous utilisons le [framework Flask](https://flask.palletsprojects.com/en/2.2.x/). L'objectif de cette partie est de comprendre le fonctionnement des serveurs Web et de s'en servir pour appeler notre mod√®le et faire de l'inf√©rence.

1. Lancez le fichier `app.py` avec la commande `python3 app.py`. Votre serveur web va se lancer et √™tre accessible via des requ√™tes HTTP. V√©rifiez que la connexion √† votre serveur fonctionne (Linux/Mac users):

```
curl localhost:5678
```

ou directement depuis votre navigateur http://localhost:5678/hello. Il est possible qu'une URL diff√©rente de `localhost` soit affich√©e dans la console ayant servi √† lancer votre programme, dans ce cas utilisez cette derni√®re.

**Notes**

- `curl` est un outil nous servant ici de client `HTTP`
- Comme vous pouvez le remarquer lorsque l'on utilise la commande `curl`, la donn√©e re√ßue est `<h1>Hello world</h1>`. Lorsque l'on ouvre notre navigateur on peut y voir apparaitre un magnifique **Hello world** format√©. Votre navigateur vous permet de formatter le HTML que vous recevez √† l'√©cran mais ce dernier n'est rien de plus qu'un client HTTP aggr√©ment√© de fonctions d'affichages.

2. Dans le dossier `templates` vous trouverez un fichier _index.html_ qui contient un code HTML un peu plus complexe qu'un simple Hello World. Cr√©er une nouvelle route `/app` permettant de renvoyer √† l'utilisateur le contenu de la page _index.html_. Il est possible d'utiliser la fonction `render_template` de Flask.
   V√©rifier que votre code fonctionne en vous rendant √† l'adresse suivante sur votre navigateur: http://localhost:5678/app.

3. Cr√©er une nouvelle route `/predict` permettant √† l'utilisateur de passer des donn√©es via un [`form`](https://www.w3schools.com/html/html_forms.asp) (requ√™te POST ou GET √† votre avis ?). Cette route devra effectuer dans l'odre:

- **Lecture des donn√©es**: nous transitons l'information de notre client vers notre backend via un formulaire. Flask permet de r√©cup√©rer ces donn√©es dans le corps de la fonction gr√¢ce √† [l'objet request](https://www.digitalocean.com/community/tutorials/processing-incoming-request-data-in-flask). Habituellement les formulaires sont utilis√©s pour les applications Web mais dans le cas de simples APIs il est pr√©f√©rable d'utiliser les formats JSON/XML/Protobuf.
- **V√©rification de la donn√©e**: est-ce que la donn√©e contient tous les champs que l'on souhaite (house_type, nb_room, ...) ? Dans le cas o√π la donn√©e est mal formatt√©e, renvoyer un [code d'erreur 400](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400).
- **Chargement du mod√®le**: apr√®s avoir sauvegard√© votre mod√®le au format `pickle`, il est temps de le recr√©er et d'y faire appel.
- **Transformation des donn√©es**: appliquer le m√™me preprocessing que lors de l'entrainement √† vos nouvelles donn√©es. Vous pouvez directement int√©grer la fonction `transform_house_type` que vous avez cod√© √† la partie pr√©c√©dente.
- **Pr√©diction**: utilisez votre mod√®le charg√© pour pr√©dire le prix √† partir des donn√©es d'entr√©e
- **Renvoi du r√©sultat**: retournez la valeur pr√©dite ainsi que le [status 200](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200).

4. V√©rifiez que votre nouvelle route fonctionne:

```bash
curl -X POST -d "postcode=75&house_type=Maison&house_surface=130&nb_room=5&garden_area=300"  localhost:5678/predict
```

Ou bien testez directement depuis la page web en remplissant le formulaire !

## Partie 3: Int√©grez le code postal √† votre model

Maintenant que vous avez r√©ussi √† d√©ployer votre premi√®re webapp faisant appel √† un mod√®le de Machine Learning, il est temps d'am√©liorer un peu tout √ßa ! L'objectif de cette partie est de rajouter le code postal √† notre mod√®le !

1. R√©cup√©rez des donn√©es permettant d'enrichir votre jeu de donn√©es d'entrainement √† partir des codes postaux. Refaire toute la premi√®re partie en prenant en compte votre/vos nouvelle(s) variable(s).

2. Retravaillez votre backend pour prendre en compte cette nouvelle variable. Il vous faudra revoir votre `preprocessing` pour y ajouter l'enrichissement de donn√©es, et votre √©tape de `validation` des donn√©es. Les donn√©es peuvent √™tre enrichies en ajoutant de nouvelles features, il est possible d'utiliser ce [dataset](https://www.insee.fr/fr/statistiques/4265429?sommaire=4265511) pour ajouter une colonne correspondant au nombre d'habitants par commune.

3. Modifier l'interface web pour ajouter un nouveau champ au formulaire. Un peu de HTML √ßa ne fait pas de mal üòÉ

4. Testez votre nouvelle application et v√©rifiez que les maisons √† Paris co√ªtent tr√®s cher !

## Partie 4: Pour aller plus loin

Cette section vous propose d'explorer diff√©rents sujets auxquels des ing√©nieurs dans le data sont confront√©s. L'objectif est de vous exposer ces probl√©matiques et libre √† vous de creuser les sujets qui vous int√©ressent les plus.

- Aujourd'hui notre application n√©cessite Python et plusieurs d√©pendances pour fonctionner correctement. Dans un contexte de production il est courant de ne pas savoir exactement sur quelle machine tourne son programme (ex: Kubernetes choisi parmi un cluster de machine). Il est impensable de devoir installer toutes les d√©pendances de tous nos programmes sur toutes les machines ! C'est pour r√©pondre √† cette probl√©matique que [Docker](https://www.docker.com/) a √©t√© cr√©√©. Il permet de cr√©er des images qui vont empaqu√™ter toutes les d√©pendances et le code n√©cessaire pour faire fonctionner notre application. L'objectif est de cr√©er une image Docker permettant de faire fonctionner notre application web correctement. Vous pouvez vous inspirer de [ce tutoriel](https://www.digitalocean.com/community/tutorials/how-to-build-and-deploy-a-flask-application-using-docker-on-ubuntu-20-04).
- `sklearn` a d√©velopp√© un objet [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) qui permet d'aggr√©ger les √©tapes de preprocessing et de prediction au sein d'un m√™me objet. Il est tout √† fait possible (et m√™me recommand√©) de s√©rializer (avec `pickle` par exemple) le mod√®le accompagn√© de sa pipeline de traitement.
  1. Plut√¥t que d'impl√©menter plusieurs fonctions comme `transform_house_type`, impl√©menter une pipeline de traitement en utilisant les transformeurs de `sklearn`.
  2. Rajoutez une √©tape de standardisation des donn√©es num√©rique. L'objet [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) le fera tr√®s bien pour vous et vous permettra de conserver l'√©cart-type et la variance de votre jeu d'entra√Ænement (qui doit √™tre r√©utilis√©e pour standardiser vos donn√©es de test !!)
  3. S√©rialisez votre pipeline et modifier votre route de pr√©diction pour la simplifier.
- `pickle` est simple d'utilisation mais n'est pas vraiment adapt√© pour des cas d'usage en production. On pr√©f√®rera des formats adapt√©s √† la s√©rialisation de pipeliene de ML comme `Open Neural Network Exchange` (ONNX). L'objectif est de transformer votre code pour exporter votre pipeline sous ce format.
- Dans notre exemple, √† chaque appel √† la route `/predict` on charge le mod√®le et on effectue l'inf√©rence. Dans un exemple tr√®s simple comme le notre cela ne pose pas de probl√®me, mais pour des applications plus gourmandes (ex: Deep Learning), le chargement des mod√®les peut prendre plusieurs minutes. Dans ces cas l√† comment faire ? Quelques id√©es √† explorer:
  - Impl√©mentez notre code en C++
  - `Quantization`: entrainer un r√©seau de neurones sur des float32 au lieu de float64 -> r√©duit la taille du mod√®le
  - `Pruning`: mani√®re de retirer les couches les moins utiles
  - `Distillation`: entra√Æner un r√©seau de neurones plus petit √† r√©pliquer les d√©cisions d'un gros r√©seau
  - Utilisation de GPU pour effectuer l'inf√©rence (pour processer des images ou du texte c'est indispensable)
- Lorsqu'on cherche √† am√©liorer notre mod√®le il est courant d'augmenter la taille de notre jeu de de donn√©es d'entrainement, de rechercher les meilleurs hyperparam√®tres, de repenser l'architecture, ... De fait, on ne peut pas se permettre de repasser par la phase exploratoire dans un Jupyter Notebook, de r√©entrainer notre mod√®le, de le packager et de remplacer le mod√®le existant par le nouveau. En pratique toutes ces √©tapes sont automatis√©es gr√¢ce √† des pipelines sp√©cifiques. Cette automatisation rentre dans le scope du `MLOps` (Machine Learning Operations). On vous invite √† vous renseigner sur ces principes gr√¢ce √† cet excellent site https://ml-ops.org/. Cette discipline est √† cheval entre plusieurs m√©tier: `Data Scientist`, `Data Engineer`, `Software Engineer` et `DevOps`.
